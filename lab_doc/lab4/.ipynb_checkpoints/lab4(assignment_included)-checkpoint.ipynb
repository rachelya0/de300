{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedd0184",
   "metadata": {},
   "source": [
    "# Loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afbfdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#required for reading .xml files\n",
    "import xml.etree.ElementTree as ET\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "#required for navigating machine's directory\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "#required for communicating with SQL database\n",
    "from sqlalchemy import create_engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2df180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the postgresql address for SQL base coonection\n",
    "conn_string = 'postgresql://admin:de300SPRING2024@dd300spring2024.549787090008.us-east-2.redshift-serverless.amazonaws.com:5439/dev'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12401535",
   "metadata": {},
   "source": [
    "### Utility function for writing data into the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05c7e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_table(data: pd.DataFrame, table_name:str):\n",
    "    db = create_engine(conn_string)\n",
    "    conn = db.connect()\n",
    "    data.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee295b4d",
   "metadata": {},
   "source": [
    "# Step one : Extract data from ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d928b34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/used_car_prices2.xml\n",
      "./data/used_car_prices3.json\n",
      "./data/used_car_prices2.csv\n",
      "./data/used_car_prices3.xml\n",
      "./data/used_car_prices1.xml\n",
      "./data/used_car_prices2.json\n",
      "./data/used_car_prices3.csv\n",
      "./data/used_car_prices1.json\n",
      "./data/used_car_prices1.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob('./data/*')\n",
    "\n",
    "# Output the list of files\n",
    "for file in all_files:\n",
    "    print(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d2a39",
   "metadata": {},
   "source": [
    "### Function to extract data from one .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7837037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process: str) -> pd.DataFrame:\n",
    "    \n",
    "    # add you line here to read the .csv file and return dataframe\n",
    "    df = pd.read_csv(file_to_process)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5be00",
   "metadata": {},
   "source": [
    "### Function to extract data from one .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fc7e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_from_json(file_to_process: str) -> pd.DataFrame:\n",
    "    \n",
    "    # add you line here to read the .json file and return dataframe\n",
    "    df = pd.read_json(file_to_process,lines=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ffb74",
   "metadata": {},
   "source": [
    "### Function to extract data from one  .xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c0c08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process: str) -> pd.DataFrame:\n",
    "    dataframe = pd.DataFrame(columns = columns)\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        sample = pd.DataFrame({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, index = [0])\n",
    "        dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10537c6b",
   "metadata": {},
   "source": [
    "### Function to extract data from the ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19cb67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract() -> pd.DataFrame:\n",
    "    extracted_data = pd.DataFrame(columns = columns)\n",
    "    #for csv files\n",
    "    for csv_file in glob.glob(os.path.join(folder, \"*.csv\")):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
    "    \n",
    "    #add lines for json files\n",
    "    for json_file in glob.glob(os.path.join(folder, \"*.json\")):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(json_file)], ignore_index=True)\n",
    "    \n",
    "    #add lines for xml files\n",
    "    for xml_file in glob.glob(os.path.join(folder, \"*.xml\")):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(xml_file)], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a192e",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a120192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3569/3225141769.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "columns = ['car_model','year_of_manufacture','price', 'fuel']\n",
    "folder = \"data\"\n",
    "#table_name = \"car_data\"\n",
    "\n",
    "# run\n",
    "def main():\n",
    "    data = extract()\n",
    "    #insert_to_table(data, \"car_data\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62b33037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3569/3225141769.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_3569/2138107605.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb9cee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alto 800</td>\n",
       "      <td>2017</td>\n",
       "      <td>4253.731343</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2015</td>\n",
       "      <td>10223.880597</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2015</td>\n",
       "      <td>11194.029851</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ertiga</td>\n",
       "      <td>2015</td>\n",
       "      <td>9104.477612</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dzire</td>\n",
       "      <td>2009</td>\n",
       "      <td>3358.208955</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>etios liva</td>\n",
       "      <td>2014</td>\n",
       "      <td>7089.552239</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>innova</td>\n",
       "      <td>2017</td>\n",
       "      <td>29477.611940</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fortuner</td>\n",
       "      <td>2010</td>\n",
       "      <td>13805.970149</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2011</td>\n",
       "      <td>6492.537313</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2016</td>\n",
       "      <td>21268.656716</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_model year_of_manufacture         price    fuel\n",
       "0        alto 800                2017   4253.731343  Petrol\n",
       "1            ciaz                2015  10223.880597  Diesel\n",
       "2            ciaz                2015  11194.029851  Petrol\n",
       "3          ertiga                2015   9104.477612  Petrol\n",
       "4           dzire                2009   3358.208955  Petrol\n",
       "..            ...                 ...           ...     ...\n",
       "85     etios liva                2014   7089.552239  Diesel\n",
       "86         innova                2017  29477.611940  Petrol\n",
       "87       fortuner                2010  13805.970149  Diesel\n",
       "88  corolla altis                2011   6492.537313  Petrol\n",
       "89  corolla altis                2016  21268.656716  Petrol\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2da7c-4637-4659-9ca4-71084c132e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert_to_table(data = data, table_name = 'extracted_cars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2892f",
   "metadata": {},
   "source": [
    "# Step Two: Transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_file = \"cars.parquet\"\n",
    "staging_data_dir = \"staging_data\"\n",
    "\n",
    "def transform(df):\n",
    "    # db = create_engine(conn_string)\n",
    "\n",
    "    # df = pd.read_sql_query(f'SELECT * FROM {table_name}',con=db)\n",
    "\n",
    "    print(f\"Shape of data {df.shape}\")\n",
    "\n",
    "    # truncate price with 2 decimal place (add your code below)\n",
    "    df['price'] = df['price'].round(2)\n",
    "\n",
    "    # remove samples with same car_model (add your code below)\n",
    "    df = df.drop_duplicates(subset=['car_model'], keep='first')\n",
    "    \n",
    "    print(f\"Shape of data {df.shape}\")\n",
    "\n",
    "    # write to parquet\n",
    "    df.to_parquet(os.path.join(staging_data_dir, staging_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(data)\n",
    "#print the head of your data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d995c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Step Three : Loading data for further modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c20ccef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "# read from the .parquet file\n",
    "\n",
    "def load() -> pd.DataFrame:\n",
    "    data = pd.DataFrame()\n",
    "    for parquet_file in glob.glob(os.path.join(staging_data_dir, \"*.parquet\")):\n",
    "        data = pd.concat([pd.read_parquet(parquet_file),data])\n",
    "\n",
    "    #insert_to_table(data, table_name)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a727c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1f0462",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d66cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed7fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012aec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217848c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28764ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e276b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
